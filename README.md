# ğŸ§  SNARK â€” The Sarcastic AI Sidekick

> *â€œYou asked for help? Hereâ€™s some sass with your solution.â€*

Meet **Snark**, the AI-powered web assistant who answers with a scowl and serves solutions with sass. Born out of late-night frustration and too much caffeine, Snark is your overqualified, underpaid sarcastic buddy whoâ€™s always online (if youâ€™re lucky). It's like ChatGPT, but with a grudge.
But remember it always solves your issues, thats whats its made for! :)
---

## ğŸ¯ Features

- âš¡ **Real-time chat** interface â€” just like your fav AI chatbots.
- ğŸ˜ˆ **Biting sarcasm** baked into every reply.
- ğŸª„ **Magical backend** powered by an ultra-fast LLM API.
- ğŸŒ **Frontend + Backend** fully connected using Cloudflare Tunnel.
- ğŸ’» **Simple VS Code setup (or even colab if your the GPU fast guy XD butt remember it wont do the GUI then)** â€” clone, install, run. As fun and simple as that!

---

## ğŸ“¦ Tech Stack

| Layer      | Tech                  |
|------------|------------------------|
| Frontend   | Next.js (React + TS)   |
| Backend    | Node.js + Express      |
| Styling    | Tailwind CSS           |
| API Calls  | Fetch (REST)           |
| Hosting    | Cloudflare Tunnel      |

---

## ğŸš€ Getting Started

### 1. Clone the repo

```
git clone https://github.com/your-username/snark.git
cd snark
2. Install dependencies

cd backend
npm install

cd ../frontend
npm install
3. Set your API key
Create a .env file inside /backend and add:

GROQ_API_KEY=your_api_key_here
(Youâ€™ll get the key from groq.com. Itâ€™s free to register.)

4. Start servers

# Start backend (port 5000)
cd backend
npm run dev

# In a new terminal, start frontend (port 3000)
cd frontend
npm run dev
ğŸŒ Expose to the world (Optional)
To make Snark accessible globally, use Cloudflare Tunnel. Example:

cloudflared tunnel --url http://localhost:3000
This will give you a .trycloudflare.com URL you can share anywhere. So yeah you flex on your friends that you made this (i bet they dont know cake about open source XD)
```
ğŸ”Œ API + Model
Snark uses an external AI inference API to generate replies. It's built to be OpenAI-compatible but operates on open-weight models with insanely low latency â€” perfect for real-time sass.

This makes Snark fast, free, and fierce.

You only need one key (provided via .env) to start generating snarky magic. No complex setup. Just plug and play.

# ğŸ§  Powered by Groq (tho models vary)
Snark taps into the **Groq API** for *blink-and-you-miss-it* fast responses, ensuring your sarcasm gets delivered before your patience runs out.  
Itâ€™s like having the internetâ€™s meanest friend, but running at SSD speed.

ğŸ¤– Why Snark is Special
Most AI bots are polite. Snark? Not so much. It talks back, it rolls its eyes, and it still gives you brilliant answers. Itâ€™s not just code â€” itâ€™s attitude-as-a-service.

Ideal for devs who love sarcasm with their solutions.

ğŸ’¬ Example Use Cases
Pair programming with an attitude

Testing LLM-powered UI ideas

Making your friends feel roasted by a bot

ğŸ§¼ .gitignore
A basic .gitignore is included to skip:

node_modules/
.env
dist/
.next/
ğŸªª License
MIT â€” because Snark doesn't believe in gatekeeping.

ğŸ§  Fun Fact
The first reply Snark ever made was:
â€œSummoned from digital purgatory just to solve your gen z issue? I miss death, frâ€
